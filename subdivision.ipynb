{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import yaml\n",
    "import torch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "solver_dir = \"/home/ubuntu/SML/solver\"\n",
    "\n",
    "sys.path.append(solver_dir)\n",
    "\n",
    "file_path = \"/home/ubuntu/SML/solver/solver.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"solver\", file_path)\n",
    "solver = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 113.8e9\n",
    "nu = 0.342\n",
    "rho = 4.47e-3\n",
    "\n",
    "device = \"cuda:2\"\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "with open(f'/data/SimJEB/boundary/{i}.yaml') as file:\n",
    "    boundary = yaml.safe_load(file)\n",
    "    rbe2 = torch.cat([torch.tensor(rbe2['slaves']) for rbe2 in boundary['rbe2']]).to(device)\n",
    "    rbe3 = torch.cat([torch.tensor(rbe3['slaves']) for rbe3 in boundary['rbe3']]).to(device)\n",
    "\n",
    "coords, elements = solver.vtk_loader_to_torch(f'/data/SimJEB/vtk/{i}.vtk', 'c3d4')\n",
    "coords = coords.to(device)\n",
    "elements = elements.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([589]) torch.Size([753]) torch.Size([112873, 3]) torch.Size([570111, 4])\n"
     ]
    }
   ],
   "source": [
    "print(rbe2.shape, rbe3.shape, coords.shape, elements.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([570111, 12, 12])\n",
      "Memory allocated on GPU for element wise K: 0.3341 GB\n"
     ]
    }
   ],
   "source": [
    "K = solver.compute_K_matrix(coords, elements, 'c3d4', E, nu, device=device, dtype=dtype)\n",
    "print(K.shape)\n",
    "print(f\"Memory allocated on GPU for element wise K: {torch.cuda.memory_allocated(K.device) / 1024**3:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([338619, 338619])\n",
      "Memory allocated on GPU for sparse K: 2.8827 GB\n"
     ]
    }
   ],
   "source": [
    "M = K.shape[0]\n",
    "\n",
    "node_indices = elements.unsqueeze(-1).repeat(1, 1, 3)\n",
    "dof_indices = node_indices * 3 + torch.arange(3, device=device).view(1, 1, 3)\n",
    "dof_indices = dof_indices.view(M, -1)\n",
    "\n",
    "row_idx = dof_indices.unsqueeze(2).repeat(1, 1, 12).view(-1)\n",
    "col_idx = dof_indices.unsqueeze(1).repeat(1, 12, 1).view(-1)\n",
    "values = K.view(-1)\n",
    "\n",
    "N_nodes = elements.max().item() + 1\n",
    "N_dof = N_nodes * 3\n",
    "\n",
    "K_sparse = torch.sparse_coo_tensor(\n",
    "    indices=torch.stack([row_idx, col_idx]),\n",
    "    values=values,\n",
    "    size=(N_dof, N_dof),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(K_sparse.shape)\n",
    "print(f\"Memory allocated on GPU for sparse K: {torch.cuda.memory_allocated(K_sparse.device) / 1024**3:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def compute_subdivisions(matrix_size, gpu_memory_gb):\n",
    "    bytes_per_float = 4  # float32\n",
    "    max_bytes = gpu_memory_gb * (1024 ** 3)\n",
    "    max_elements = max_bytes // bytes_per_float\n",
    "    max_dim = int(math.floor(math.sqrt(max_elements)))\n",
    "    subdivisions = math.ceil(matrix_size / max_dim)\n",
    "    return subdivisions\n",
    "\n",
    "print(compute_subdivisions(K_sparse.shape[0], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1097840])\n",
      "Memory allocated on GPU for edge: 2.8991 GB\n"
     ]
    }
   ],
   "source": [
    "edge = solver.identify_tetrahedral_shared_faces(elements, device=device)\n",
    "edge = torch.cat([edge[:,0,0].unsqueeze(0), edge[:,1,0].unsqueeze(0)], dim=0)\n",
    "print(edge.shape)\n",
    "print(f\"Memory allocated on GPU for edge: {torch.cuda.memory_allocated(edge.device) / 1024**3:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_matrix(edge, num_elements, device):\n",
    "    edge = edge.to(device)\n",
    "    indices = torch.cat([edge, edge[[1, 0]]], dim=1)\n",
    "    values = torch.ones(indices.shape[1], device=device)\n",
    "    adj = torch.sparse_coo_tensor(indices, values, size=(num_elements, num_elements), device=device)\n",
    "    return adj.coalesce()\n",
    "\n",
    "def pick_distant_seeds(adj, n_parts):\n",
    "    N = adj.shape[0]\n",
    "    device = adj.device\n",
    "    seeds = [torch.randint(0, N, (1,), device=device).item()]\n",
    "    selected_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    selected_mask[seeds[0]] = True\n",
    "\n",
    "    for _ in range(n_parts - 1):\n",
    "        dist = torch.full((N,), float('inf'), device=device)\n",
    "        frontier = selected_mask.clone().float()\n",
    "        current_dist = 0\n",
    "\n",
    "        while frontier.sum() > 0:\n",
    "            newly_visited = (dist == float('inf')) & (frontier > 0)\n",
    "            dist = torch.where(newly_visited, current_dist, dist)\n",
    "            frontier = torch.sparse.mm(adj, frontier.unsqueeze(1)).squeeze() > 0\n",
    "            frontier = frontier & (dist == float('inf'))\n",
    "            frontier = frontier.float()\n",
    "            current_dist += 1\n",
    "\n",
    "        farthest = torch.argmax(dist).item()\n",
    "        seeds.append(farthest)\n",
    "        selected_mask[farthest] = True\n",
    "\n",
    "    return torch.tensor(seeds, device=device)\n",
    "\n",
    "def region_growing_partition(edge, n_parts, num_elements, device=\"cuda:2\"):\n",
    "    device = torch.device(device)\n",
    "    adj = build_adjacency_matrix(edge, num_elements, device)\n",
    "    seeds = pick_distant_seeds(adj, n_parts)\n",
    "\n",
    "    labels = torch.full((num_elements,), -1, dtype=torch.long, device=device)\n",
    "    labels[seeds] = torch.arange(n_parts, device=device)\n",
    "\n",
    "    frontier = torch.zeros((n_parts, num_elements), dtype=torch.bool, device=device)\n",
    "    frontier[torch.arange(n_parts), seeds] = True\n",
    "\n",
    "    while (labels == -1).any():\n",
    "        expanded = torch.sparse.mm(adj, frontier.float().T).T > 0\n",
    "        expanded = expanded & (labels == -1).unsqueeze(0)\n",
    "        new_indices = expanded.nonzero(as_tuple=False)\n",
    "        labels[new_indices[:, 1]] = new_indices[:, 0]\n",
    "        frontier = expanded\n",
    "\n",
    "    groups = [torch.nonzero(labels == i, as_tuple=True)[0] for i in range(n_parts)]\n",
    "    return groups, seeds\n",
    "\n",
    "def build_sparse_K_local(K, elements, element_indices, device=\"cuda:2\"):\n",
    "    device = torch.device(device)\n",
    "    K = K.to(device)\n",
    "    elements = elements.to(device)\n",
    "    K_part = K[element_indices]\n",
    "    elems = elements[element_indices]\n",
    "\n",
    "    global_nodes = torch.unique(elems)\n",
    "    global_to_local = {int(n): i for i, n in enumerate(global_nodes.tolist())}\n",
    "    flat_elems = elems.view(-1).tolist()\n",
    "    local_node_ids = torch.tensor([global_to_local[n] for n in flat_elems], device=device).view(elems.shape)\n",
    "    elems_local = local_node_ids\n",
    "\n",
    "    node_idx = elems_local.unsqueeze(-1).repeat(1, 1, 3)\n",
    "    dof_idx = node_idx * 3 + torch.arange(3, device=device).view(1, 1, 3)\n",
    "    dof_idx = dof_idx.view(len(elems_local), -1)\n",
    "\n",
    "    row_idx = dof_idx.unsqueeze(2).repeat(1, 1, 12).view(-1)\n",
    "    col_idx = dof_idx.unsqueeze(1).repeat(1, 12, 1).view(-1)\n",
    "    values = K_part.view(-1)\n",
    "\n",
    "    N_nodes = elems_local.max().item() + 1\n",
    "    N_dof = N_nodes * 3\n",
    "\n",
    "    K_local = torch.sparse_coo_tensor(\n",
    "        indices=torch.stack([row_idx, col_idx]),\n",
    "        values=values,\n",
    "        size=(N_dof, N_dof),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return K_local, global_nodes\n",
    "\n",
    "def partition_and_build_sparse_K(K, elements, edge, n_parts, device=\"cuda:2\"):\n",
    "    device = torch.device(device)\n",
    "    groups, seeds = region_growing_partition(edge, n_parts, K.shape[0], device=device)\n",
    "    K_parts = []\n",
    "    node_maps = []\n",
    "    for g in groups:\n",
    "        K_local, global_nodes = build_sparse_K_local(K, elements, g, device=device)\n",
    "        K_parts.append(K_local)\n",
    "        node_maps.append(global_nodes)\n",
    "    return K_parts, node_maps, groups, seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_parts, node_maps, element_groups, seeds = partition_and_build_sparse_K(K, elements, edge, n_parts=20, device=\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated on GPU for partitioned sparse K:  4.4562 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory allocated on GPU for partitioned sparse K: \", f\"{torch.cuda.memory_allocated(K.device) / 1024**3:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated on GPU for partitioned inverted sparse K:  39.8502 GB\n"
     ]
    }
   ],
   "source": [
    "def invert_K_parts(K_parts):\n",
    "    K_inverses = []\n",
    "    for K in K_parts:\n",
    "        K_dense = K.to_dense()\n",
    "        K_inv = torch.linalg.inv(K_dense)\n",
    "        K_inverses.append(K_inv)\n",
    "    return K_inverses\n",
    "\n",
    "K_inverses = invert_K_parts(K_parts)\n",
    "print(\"Memory allocated on GPU for partitioned inverted sparse K: \", f\"{torch.cuda.memory_allocated(K.device) / 1024**3:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "def build_ordered_subdomain_map(node_maps):\n",
    "    node_groups = {}\n",
    "    for sd_idx, nds in enumerate([nm.cpu().tolist() for nm in node_maps]):\n",
    "        for nd in nds:\n",
    "            if nd not in node_groups:\n",
    "                node_groups[nd] = set()\n",
    "            node_groups[nd].add(sd_idx)\n",
    "    group_to_nodes = defaultdict(list)\n",
    "    for nd, sds in node_groups.items():\n",
    "        if len(sds)>1:\n",
    "            group_to_nodes[tuple(sorted(sds))].append(nd)\n",
    "    return dict(group_to_nodes)\n",
    "\n",
    "group_to_nodes = build_ordered_subdomain_map(node_maps)\n",
    "print(len(group_to_nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11369, 3])\n"
     ]
    }
   ],
   "source": [
    "free_variables = []\n",
    "for k, v in group_to_nodes.items():\n",
    "    free_variables.extend([[0,0,0]]*((len(k)-1)*len(v)))\n",
    "free_varibles = torch.tensor(free_variables, device=device)\n",
    "print(free_varibles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sub_domain_forces(free_vars, group_to_nodes, rbe2, F, n_sub, device=\"cuda\"):\n",
    "    s = [F.clone().to(device) for i in range(n_sub)]\n",
    "    off = 0\n",
    "    for k,v in group_to_nodes.items():\n",
    "        m = len(k) - 1\n",
    "        c = m * len(v)\n",
    "        chunk = free_vars[off:off + c]\n",
    "        off += c\n",
    "        idx = 0\n",
    "        sd = sorted(k)\n",
    "        for nd in v:\n",
    "            if nd in rbe2:\n",
    "                idx += m\n",
    "                continue\n",
    "            if m == 1:\n",
    "                s[sd[0]][nd] += chunk[idx]\n",
    "                s[sd[1]][nd] -= chunk[idx]\n",
    "                idx += 1\n",
    "            else:\n",
    "                s[sd[0]][nd] += chunk[idx]\n",
    "                for j in range(1,m):\n",
    "                    s[sd[j]][nd] += chunk[idx+j] - chunk[idx+j-1]\n",
    "                s[sd[m]][nd] -= chunk[idx+m-1]\n",
    "                idx += m\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt24_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
